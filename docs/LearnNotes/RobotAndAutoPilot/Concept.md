> 一些机器人与自动驾驶领域的一些概念，主要用于简单的概念解读与储备。

> 完善之后，如果可以细化，其中的内容可以拆分到具体的模块中

---

# RTK

RTK 是实时运动学（Real Time Kinematic）的缩写，是一种提高 GPS 定位测量精确度的技术。

> 相关文章

- https://www.oxts.com/zh/what-is-rtk/

---

# WebSocket

基于TCP的双向通信协议。

---

# Base64

> 基于文本的网络协议，是啥意思？

指的是使用 文本格式 来表示和传输数据的协议，这些协议在通信过程中使用的主要数据格式是可读的字符数据（如 ASCII、UTF-8 等编码方式的文本）。这些协议的目的是通过 文本 对请求和响应进行编码、传输和解析，而不是直接使用 二进制数据。

> 为什么要用Base64?

- 克服文本协议的局限性；

尤其是在需要通过基于 文本协议 的系统（如 HTTP、WebSocket、MQTT 等）传输 二进制数据 时，
主要是为了`克服文本协议的局限性`，并保证数据的`完整性`和`兼容性`。

Base64 编码的作用是将 二进制数据 转换成由 字母、数字、加号（+）、斜杠（/）和等号（=） 组成的 ASCII 字符串，这种格式完全符合文本协议的要求，可以通过文本协议传输。

- 确保数据在传输过程中的安全性

将数据转化为 纯文本字符，从而避免在传输过程中因字符处理不当导致的丢失或损坏。防止一些特殊字符的误处理和操作。

- 方便放入请求和响应中

例如: 发送图片数据，将图片转为base64，放到json数据中一起发送过去，接收端收到再解析回图片。

- 平台兼容性

Base64编码后的数据只包含保准的ASCII字符，便于不同系统和协议之间的兼容。

尽管，他会增加33%的数据体积。

> 示例:

使用protobuf序列化数据，然后通过base64编码，然后再传输。

高效二进制序列化格式 -> 文本格式

方便跨平台、跨语言，防止数据误处理。但是同时会增大数据大小。

---

# AP模式

AP模式（Access Point模式）是 无线网络 中的一种工作模式。它指的是 无线接入点（Access Point, AP） 在特定的网络环境中如何运作。

在 AP模式 下，接入点充当 无线信号的发射源，并提供一个无线网络，让其他设备（如智能手机、电脑、IoT设备等）可以连接到这个无线网络。

例如在某个系统启动后，进入AP模式，用于:

- 初始化配置，用户连接到热点，直接访问设备，给它配置家庭网络，再进行远程控制；
  - 例如: Amazon Echo 的连接手机App；

> 常见的IoT设备配网流程

1. 设备进入 AP模式 并广播 Wi-Fi 信号；
2. 用户通过手机或 PC 连接到设备的 Wi-Fi 信号；
3. 通过专用的配置页面或 App 完成设备的 Wi-Fi 配置，之后退出AP模式；

`简化配置过程，提供设备易用性。`

---

# 蓝牙服务

记录一些蓝牙服务的概念。

> 蓝牙通信的工程

配对 -> 连接 -> 服务发现 -> 数据交换

> BLE —— 低功耗蓝牙

为低功耗设备设计的蓝牙通信标准。

通信过程类似于经典蓝牙，但是在数据交换上有很大差异。

BLE 采用 GATT 协议 进行数据交换，而经典蓝牙则更多使用 RFCOMM 或 L2CAP 协议。

> GATT 通用属性协议

是BLE设备时间用于数据传输的标准协议。它定义了BLE设备如何共享数据，具体包括如何组织和交换数据。

- GATT 服务（Service）：

服务是一个 BLE 设备提供的功能块。
例如，电池电量、心率监测等，每个服务包含一组相关的特征（Characteristics）。

- GATT 特征（Characteristic）：

特征是数据单元，表示一个特定的数据点。
例如，电池电量、当前时间等。每个特征可以有一个值（如一个整数、字符串等），并且支持读写操作。

- GATT 描述符（Descriptor）：

描述符是特征的附加信息或元数据。例如，描述一个特征值的单位（摄氏度、华氏度等），或是特征的额外描述。

> BlueZ

Linux上的蓝牙协议栈，它实现了蓝牙设备之间的所有通信。允许Linux设备进行蓝牙通信，是Linux系统中用于支持蓝牙设备的标准软件。

- 它提供了D-Bus接口，使得应用程序可以通过D-Bus与蓝牙设备进行交互；
- 实现了整个蓝牙协议；

---

# SOC

System on Chinp —— `片上系统`的缩写，指的是将整个计算机或电子系统的主要功能集成在一个芯片上的技术。

---

# MCU

Microcontroller Unit —— `微控制单元`的缩写，通常指一种集成了中央处理器(CPU)、内存、外设接口等多个功能模块的单片微型计算机系统。

是嵌入式系统中最常用的计算平台，广泛应用于控制系统、物联网设备、机器人等设备中。

> .bin 文件

代表MCU 固件。

固件是嵌入式系统中运行的程序代码，负责控制和管理MCU的操作。

.bin文件包含了操作系统(如果有)、硬件控制代码、算法、驱动程序等。

---

# SOC MCU 对比

| 特性         | MCU                                         | SOC                                          |
| ------------ | ------------------------------------------- | -------------------------------------------- |
| **集成度**   | 集成处理器、内存、外设接口等，但一般不含复杂的GPU等 | 高度集成，通常包含多个CPU核心、GPU、网络接口、加速器等 |
| **计算能力** | 较弱，适合简单控制任务                     | 较强，适合图形处理、视频解码、AI处理等复杂任务 |
| **功耗**     | 低功耗                                     | 相对较高，但经过优化也可以做到低功耗          |
| **应用场景** | 控制、传感器管理、简单任务                 | 高性能设备，复杂计算任务，移动设备           |
| **示例**     | 单片机（如 STM32、Arduino）                | 高通 Snapdragon、苹果 A 系列、华为 Kirin 系列 |

---

# pub/sub

> 有趣的一个问题，为什么topic是模拟路径的样式？

- 划分层级命名空间
- 模糊订阅，例: /robot/sensor/* 
- 历史传承 —— Unix 把一些都抽象成文件

---

# 网络

## 路由

TODO

---

## DHCP

 —— Dynamic Host Configuration Protocol

是一种运行在应用层的网络协议(使用UDP端口 67 68)，为的是自动为网络中的主机(Client)分配地址及相关的网络配置参数，消除手动配置的繁琐和冲突风险。

> 工作流程 —— DORA

1.  **Discover（发现阶段）**：
    *   **客户端**以**广播**形式发送 `DHCP Discover` 报文。
    *   由于客户端此时没有 IP，源地址为 `0.0.0.0`，目标地址为 `255.255.255.255`。
    *   **意图**：寻找网络中可用的 DHCP 服务器。

2.  **Offer（提供阶段）**：
    *   **服务器**收到 Discover 后，从地址池中挑选一个未分配的 IP，向客户端发送 `DHCP Offer` 报文。
    *   **内容**：包含预分配的 IP 地址、子网掩码、租约时长、网关、DNS 等信息。

3.  **Request（请求阶段）**：
    *   **客户端**可能收到多个服务器的 Offer，通常选择第一个到达的。
    *   客户端再次发出**广播** `DHCP Request` 报文。
    *   **意图**：告诉所有服务器它接受了哪一个 Offer，以便其他服务器回收预留的地址。

4.  **Acknowledge（确认阶段）**：
    *   **服务器**发送 `DHCP Ack` 报文给客户端，正式确认 IP 分配。
    *   此时客户端正式获得 IP，开始配置自己的网络接口。

> 下发的网络参数

除了 IP 地址，DHCP还可以下发:

*   **子网掩码 (Subnet Mask)**：定义本地网段的范围；
*   **默认网关 (Default Gateway)**：指明跨网段通信的出口（IP 路由的第一跳）；
*   **DNS 服务器**：指明域名解析服务器的 IP；
*   **租约时间 (Lease Time)**：IP 地址的使用期限；
*   **NTP 服务器 (Option 42)**：提供时间同步服务器的地址（这是引发系统时间跳变的外部诱因之一）；

> 关键词

*   **租约 (Lease)**：DHCP 分配的地址不是永久的，而是“租”给你的。
*   **续租 (Renewal)**：当租约时间到达 50%（T1 时间点）时，客户端会直接向服务器发送 Request 尝试延长租约；如果失败，在 87.5%（T2 时间点）时会再次以广播形式请求续租。
*   **地址池 (Address Pool)**：服务器上可供动态分配的 IP 范围。
*   **静态绑定 (Static Reservation)**：根据客户端的 **MAC 地址** 始终分配同一个固定的 IP。

> Linux DHCP 客户端程序 —— dhclient

dhclient 是由 ISC（Internet Systems Consortium）开发的一个功能强大的 DHCP 客户端程序。它是 Linux 系统（尤其是 Ubuntu、Debian、CentOS 等）中最常用的网络配置工具之一。

- 主要工作：
  - 执行 DORA 流程：发送广播寻找服务器（Discover），接收服务器提供的 IP（Offer），请求该 IP（Request），最终确认租约（Ack）；
  - 配置网卡基础属性：自动设置网卡的 IP 地址 和 子网掩码；
  - 配置路由表：根据服务器下发的网关信息，自动在 Linux 内核中添加 默认路由（Default Gateway）；
  - 更新 DNS 配置：将服务器提供的 DNS 地址写入 /etc/resolv.conf，确保系统能解析域名；

- 关键特性： 钩子机制
  - 每当网络发生变化时，dhclient都会调用一个专门的shell脚本，通常是 /usr/sbin/dhclient-script；
  - 在执行完标准配置后，dhclient-script 会扫描 /etc/dhcp/dhclient-exit-hooks.d/ 目录下的所有自定义脚本，只要dhclient动作结束，就会运行这些脚本；

- 一个典型的使用场景：
  - 调用 wpa_supplicant 去连接特定的 WIFI；
  - 成功后，执行 dhclient wlan0 来获取ip地址；
---

# Linux系统

## 软件/硬件时钟

硬件时钟(Hardware Clock/RTC)

- 是主板上的一个独立芯片 ，通常由纽扣电池供电；
  - 即使系统关机断点，有这个纽扣电池供电，它仍会继续走动；

```BASH
hwclock -r
```

软件时钟(System Clocl/软件时间)

- 是Linux内核维护的一个软件计数器；

```BASH
date
```

clock_gettime 的参数

- 是Linux提供的获取高精度时间的系统调用；

| 参数 (clk_id) | 名称 | 基准点 (0点) | 是否受系统调时影响 (Jump) | 是否计算休眠时间 (Suspend) | 适用场景 |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **`CLOCK_REALTIME`** | 系统墙上时间 | 1970-01-01 (Epoch) | **是** | 是 | 日志记录、显示当前 UTC 时间 |
| **`CLOCK_MONOTONIC`** | 单调递增时间 | 系统启动时刻 | **否** | 否 | **传感器同步、计算 $\Delta t$、控制循环** |
| **`CLOCK_BOOTTIME`** | 系统启动时间 | 系统启动时刻 | **否** | **是** | 需要考虑休眠唤醒后的时间对齐 |
| **`CLOCK_MONOTONIC_RAW`** | 原始单调时间 | 系统启动时刻 | **否** | 否 | 极其精密的硬件频率偏移校准 |
| **`CLOCK_PROCESS_CPUTIME_ID`** | 进程 CPU 时间 | 进程启动时刻 | 否 | 否 | 测量特定进程消耗的 CPU 资源 |

```C++
#include <time.h>
#include <iostream>

uint64_t get_time_ns(clockid_t clk_id) {
    struct timespec ts;
    // 获取指定时钟源的时间
    if (clock_gettime(clk_id, &ts) == 0) {
        return (uint64_t)ts.tv_sec * 1000000000ULL + ts.tv_nsec;
    }
    return 0;
}
```

---

## 进程绑核

taskset 是 Linux 系统中用于查看或设置进程 CPU 亲和性 (CPU Affinity) 的命令。

简单来说，它通过操作内核的调度掩码（bitmask），强制规定某个进程只能在指定的 CPU 核心上运行。

> 绑定

```BASH
# algo定义核心编号，&表示后台运行
algo="1,2,3"
taskset -c $algo $app_path/navi_node &
```

> 查看绑定情况

```BASH
# 结果为十六进制掩码
taskset -p <PID>
```

> 好处

- 避免互抢资源

例如算法模块如何遇到复杂场景，CPU占用率飙升，如果没有绑核，可能会抢占其他进程的CPU时间，让其他进程没法及时处理自己的事情。

- 减少缓存失效

每个CPU核心都有自己独立的L1和L2缓存，用于过存储使用该核心的进程进程最近访问的数据。
如果不给进程绑定CPU核心，当某一时刻发生核心切换时，之前积累的缓存失效，需要重新从内存中加载。
可能会造成延迟&丢帧。

- 保证实时性

比如相机模块的进程固定在某个核心上，那么它们获取图像和处理时间戳的逻辑会很稳定，不会受到其他核心上网络抖动或磁盘写入的影响。

---

# 图像

> 图像相关内容

## 相机时间戳是干嘛用的？

1. 多传感器对齐；
2. 延迟可见化；
3. 帧顺序与丢帧判断；
4. 算法层面的物理一致性；

---

## 相机采样率

> 例如 10hz代表什么

理想情况下每100ms一帧数据，(但更多的其实是平均时间)。

---

## IMU和图像的关系

1. 两帧图像之间会有IMU数据填充；
2. 算法根据图像曝光那一刻最接近的一组IMU数据，可以获取这张照片的瞬时状态；
3. 时间互补；
   1. IMU 高频率 精确捕捉快速运动，但会积累漂移；
   2. 相机 低频率 能提供全局环境信息，校正漂移；
4. 空间互补；
   1. IMU给出设备的运动变化 (位姿、加速度)；
   2. 相机提供环境特征，用来定位、建图、识别；

Camera和IMU通常都在一个物理模组中。
---

# 传感器

> 记录物联网机器人中常见的一些传感器外设

## IMU

IMU(惯性测量单元) 不是单一的传感器，而是一个“组合包”，里面装了几个不同的传感器，就像一个小型电子盒子，负责测量设备运动相关的信息。

大多数 IMU 通常都会包含的三类传感器，它们各自负责测量不同的物理量:

1. 加速度计（Accelerometer）：测线性加速度，也就是设备直线移动的快慢和方向；
2. 陀螺仪（Gyroscope）：测角速度，也就是设备旋转的快慢和方向；
3. 磁力计（Magnetometer，可选）：测地球磁场，用来判断设备的朝向；

> IMU 帧率

也叫更新率、采样率，指的是IMU传感器每秒钟输出数据的次数。

- 例: 200Hz，表示每秒钟输出200组数据，每组数据包中包含加速度、角速度等信息。

- 单位: 赫兹(Hz)，等于“每秒钟次数”。

帧率高，意味着:

- 数据更新快，更能捕捉快速运动；
- 对姿态控制和短期运动推算更加精确；

帧率低，意味着:

- 无法捕捉高速运动细节；
- 运动信息可能出现滞后或者不够平滑；

通常IMU帧率要比相机高很多，也就是为什么 IMU 可以填补两帧图像之间的运动信息，让视觉-惯性融合系统更加精准。

> 时间戳

- IMU时间戳必须和相机或者其他传感器的时间参考一致，才能正确融合；
- 时间戳如果出错，则无法准确推算速度、位置或角度变化；

---

## GNSS

GNSS 全称是 Global Navigation Satellite System——“全球导航卫星系统”的缩写。

它不是一个单一系统，而是所有全球卫星定位系统的统称。

在机器人和自动驾驶领域，它被归类为外部感知传感器(Exteroceptive Sensor)或定位传感器(Positioning Sensor)。

从功能上讲，它感知的物理量是电磁波的传播时间，并将其转化成位置、速度、时间数据。

NMEA 和 RTCM 是 GNSS 领域最核心的两种 “语言”，即 GNSS 给出的两种核心数据。

> NMEA (National Marine Electronics Association)

它是GNSS模块的标准输出，汇报位置、同步时间。


> RTCM (Radio Technical Commission for Maritime Services)

它实现RTK (厘米级高精度定位)的查分修正数据，大幅提高定位精度。

---

# 系统时钟跳变对软件算法的影响

TODO: 抽离出来，作为单独的文章

> 背景 & 为什么要更新系统时间?

在原本我们的系统中并不强调系统软件&硬件时间的准确性，为了保护数据采集（算法），NTP服务也关闭了，但是接入AWS KVS网络摄像头后，连接KVS服务器时，处于对安全性的考虑，对系统软件时间有着严格的限制，只能与真实的UTC时间相差±5分钟。

已有的同步时间逻辑，在系统上电后的GPS同步，一但搜不到GSP信号，则无法更新，之后，则是只能在系统第一次联网后，更新硬件时间，但是KVS底层获取的是软件时间。

- 一个简短的尝试。

在最开始，我尝试修改KVS源码的时间来源，使用第一次请求，保存当前硬件时间，后续每次请求时，基于当前上电时间作为偏移量，来计算当前时间，不过验证后，单纯修改KVS是不够，因为同样在TLS建链时，也会获取自己的时间戳，我们对KVS的修改，影响不到他，而修改BoringSSL底层依赖，又感觉大费周章，没有意义，最终只能放弃。

而强行更新系统软件时间，则会引起时间跳变，对已有的软件算法造成影响。所以我们需要在各个模块合适的时间点，注入我们新提供的接口——上电时间(CLOCK_MONOTONIC)，作为新的时间戳源头。

> 产生的影响

系统外围传感器，包括: GNSS、底盘、轮速、相机、IMU；

> 目标

一个鲁棒的机器人系统，其底层传感器链路（GNSS、底盘、相机、IMU）必须运行在一个**不受外界干扰、单调递增的物理时间轴（CLOCK_MONOTONIC）**上，从而实现“业务轴（墙上时间）”与“算法轴（上电时间）”的彻底隔离。

> 解决

真正的解决方法。

- 同步依赖系统时间戳的消费者 —— 所有传感器模块，在获取MCU数据后，用系统上电时间包装。
- 联网&云端上线后，同步系统软件时间；

提供统一公共接口

- 定义&实现两个获取系统上电时间MS/NS的函数，以供需要的地方调用；
  - 不过我只能通过终端监测topic来验证，我无权查看算法仓库代码，连仓库的权限都没有；


Camera和IMU

- 相机模组本身就暴露了时间戳来源的参数，修改为上电时间即可；
  - 用于修改从相机SDK get处视频帧里面time_stamp字段的时间戳，与自定义接口来源统一；

- ROS echo topic来验证

```BASH
header:
	seq:0
	stamp:
		secs:1944
		nsecs:313421000
	frame_id:camera1
...
...
...
data:. diff 946683110411.191772 ms
```

- 其中 secs 只是一个单纯的获取图像时的时间戳值，本质上就是一个时间标签，由之前的UTC时间 --> 系统上电时间。
  - 此时修改系统时间，发现这个值并不会产生跳变，即，修改成功。
- IMU 数据同理。

GNSS

- 在读取串口消息后修改:
  - RTCM 消息发布处；
  - NMEA 消息发布处；
  - GGA 定位信息发布处；
  - 基准站 LLA 发布处；



BASE




---






> 概念补充

NTP(Network Time Protocol) 网络时间协议

- 概念: 用于同步计算机系统时钟的一种网络协议，它通过UDP端口123与远程时间服务器通信；
- 目标: 将设备的系统软件时间(CLOCK_REALTIME)调整至与全球协调世界时(UTC)一致；
- 精度: 局域网内可达到毫秒级，广域网通常为几十毫秒；
- 两种校时模式：
  - 步进/跳变: 直接调用settimeofday 或 date -s ，直接将系统时间调整至目标时间；
  - 渐进/平滑: 通过adjtime微调内核时钟频率，让系统时钟跑的快一些/慢一些，直到追上目标时间；
- 注意: 一个成熟的系统/架构，软件/算法应无视系统时间跳变，防止对算法等依赖时间的操作造成影响，可以使用系统单调递增的上电时间，例如: CLOCK_MONOTONIC/CLOCK_BOOTTIME；

> 验证

TODO

